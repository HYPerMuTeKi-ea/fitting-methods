#线性回归
from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(X, y)
a = lin_reg.intercept_
b = lin_reg.coef_
a,b#回归系数和截距
#画图
plt.plot(X_new, y_predict, "r-", linewidth=2, label="Predictions")
plt.plot(X, y, "b.")
plt.xlabel("$x_1$", fontsize=18)
plt.ylabel("$y$", rotation=0, fontsize=18)
plt.legend(loc="upper left", fontsize=14)
plt.axis([0, 2, 0, 15])
plt.show()






#加权线性回归
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# 生成一些样本数据
np.random.seed(42)
X = np.random.rand(100, 1) * 10  # 特征数据，范围为[0, 10]
y = 2.5 * X + np.random.randn(100, 1) * 5  # 标签数据，带有一些噪声

# 设置样本权重（例如，较小的X值样本有较大的权重）
weights = np.where(X < 5, 2, 0.5).flatten()

# 创建并拟合加权线性回归模型
model = LinearRegression()
model.fit(X, y, sample_weight=weights)

# 打印模型的系数和截距
print(f"Coefficients: {model.coef_[0][0]:.2f}")
print(f"Intercept: {model.intercept_[0]:.2f}")

# 绘制数据点和拟合线
plt.figure(figsize=(10, 6))
plt.scatter(X, y, color='skyblue', label='Data points', alpha=0.7)
plt.plot(X, model.predict(X), color='red', linewidth=2, label='Weighted Linear Regression Fit')
plt.title('Weighted Linear Regression')
plt.xlabel('X')
plt.ylabel('y')
plt.legend()
plt.show()







#泊松分布
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# 生成一些样本数据
np.random.seed(42)
X = np.random.rand(100, 1) * 10  # 特征数据，范围为[0, 10]
y = 2.5 * X + np.random.randn(100, 1) * 5  # 标签数据，带有一些噪声

# 设置样本权重（例如，较小的X值样本有较大的权重）
weights = np.where(X < 5, 2, 0.5).flatten()

# 创建并拟合加权线性回归模型
model = LinearRegression()
model.fit(X, y, sample_weight=weights)

# 打印模型的系数和截距
print(f"Coefficients: {model.coef_[0][0]:.2f}")
print(f"Intercept: {model.intercept_[0]:.2f}")

# 绘制数据点和拟合线
plt.figure(figsize=(10, 6))
plt.scatter(X, y, color='skyblue', label='Data points', alpha=0.7)
plt.plot(X, model.predict(X), color='red', linewidth=2, label='Weighted Linear Regression Fit')
plt.title('Weighted Linear Regression')
plt.xlabel('X')
plt.ylabel('y')
plt.legend()
plt.show()

#带有error bar 的一元线性回归

import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# 生成模拟数据
np.random.seed(0)
x = np.array([0,0.35,0.6,0.9,1.2,1.3,1.4])
y = np.array([400,450,500,550,600,650,700]) # 生成线性数据并添加噪声
y_err = 0.1  # 生成误差
x_err=10
# 使用scipy进行线性回归
slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)

# 预测y值
y_pred = slope * x + intercept

# 创建图表
plt.figure(figsize=(10, 6))

# 绘制带误差棒的原始数据
plt.errorbar(x, y, xerr=x_err,yerr=y_err, fmt='o', label='Data with error bars', capsize=5)

# 绘制线性回归拟合线
plt.plot(x, y_pred, color='red', label=f'Linear fit: y={slope:.2f}x+{intercept:.2f}')

# 添加图例和标签
plt.title('Linear Regression with Error Bars')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
#打印slope 和intercept即可。
print(intercept,slope)
# 显示图表
plt.show()
